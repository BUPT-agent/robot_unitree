from openai import OpenAI
from config import ACTION_MAP, get_action_prompt_text, LLM_API_KEY, LLM_BASE_URL, LLM_MODEL


class RobotBrain:
    def __init__(self):
        self.client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
        self.model = LLM_MODEL

        # === è®°å¿†æ¨¡å—é…ç½® ===
        self.history = []
        # 10è½®å¯¹è¯ = 10æ¡ç”¨æˆ·æ¶ˆæ¯ + 10æ¡åŠ©æ‰‹æ¶ˆæ¯ = 20æ¡è®°å½•
        self.max_history_items = 2

        # === åŠ¨ä½œåˆ¤æ–­ Prompt ===
        self.action_system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªæœºå™¨äººåŠ¨ä½œæŒ‡ä»¤åˆ†ç±»å™¨ã€‚ç”¨æˆ·ä¼šè¾“å…¥ä¸€å¥è¯ï¼Œè¯·åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œç‰©ç†åŠ¨ä½œã€‚\n"
            f"{get_action_prompt_text()}\n"
            "è§„åˆ™ï¼š\n"
            "1. å¦‚æœéœ€è¦æ‰§è¡ŒåŠ¨ä½œï¼Œè¯·ä¸¥æ ¼åªè¿”å›å¯¹åº”çš„ ID æ•°å­—ã€‚\n"
            "2. å¦‚æœä¸éœ€è¦åŠ¨ä½œæˆ–åŠ¨ä½œä¸åœ¨åˆ—è¡¨ä¸­ï¼Œè¯·ä¸¥æ ¼åªè¿”å› -1ã€‚\n"
            "3. åªè¾“å‡ºæ•°å­—ï¼Œä¸è¦æ ‡ç‚¹ã€‚"
        )

    def update_history(self, role, content):
        """æ›´æ–°å¯¹è¯å†å²ï¼Œå¹¶ä¿æŒåœ¨é™åˆ¶é•¿åº¦å†…"""
        self.history.append({"role": role, "content": content})

        # ç¡®ä¿å†å²è®°å½•ä¸è¶…è¿‡è®¾å®šæ¡æ•° (20æ¡)
        while len(self.history) > self.max_history_items:
            self.history.pop(0)  # ç§»é™¤æœ€è€çš„ä¸€æ¡

    def _call_llm(self, messages, temperature=0.7):
        try:
            # print(f"ğŸ“¡ Sending {len(messages)} msgs to LLM...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ LLM API Error: {str(e)}")
            return None

    def analyze_action(self, user_text):
        """åˆ¤æ–­ç”¨æˆ·æ„å›¾æ˜¯å¦åŒ…å«åŠ¨ä½œ"""
        messages = [
            {"role": "system", "content": self.action_system_prompt},
            {"role": "user", "content": user_text}
        ]
        # æ¸©åº¦ä¸º0ï¼Œç¡®ä¿åŠ¨ä½œè¯†åˆ«å‡†ç¡®
        result = self._call_llm(messages, temperature=0.0)

        try:
            action_id = int(result)
            if action_id in ACTION_MAP:
                return ACTION_MAP[action_id]
        except (ValueError, TypeError):
            pass
        return None

    def get_chat_reply(self, user_text, action_data=None):
        """
        è·å–å›å¤ (åŒ…å«å†å²ä¸Šä¸‹æ–‡ + åŠ¨ä½œä¸Šä¸‹æ–‡)
        """
        # 1. æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªUnitree G1æœºå™¨äººåŠ©æ‰‹ï¼Œæ€§æ ¼æ´»æ³¼ã€å¹½é»˜ã€‚è¯·ç”¨å£è¯­åŒ–ã€ç®€çŸ­çš„æ–¹å¼å›ç­”ç”¨æˆ·ï¼Œå­—æ•°æ§åˆ¶åœ¨30å­—ä»¥å†…ã€‚"

        # 2. æ„å»ºå®Œæ•´æ¶ˆæ¯é“¾ï¼šSystem -> History -> Current User Input
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(self.history)  # æ”¾å…¥æœ€è¿‘10è½®å¯¹è¯
        messages.append({"role": "user", "content": user_text})

        # 3. è°ƒç”¨ LLM
        reply = self._call_llm(messages, temperature=0.8)

        # 4. æ›´æ–°è®°å¿†
        self.update_history("user", user_text)
        if reply:
            self.update_history("assistant", reply)

        return reply

    def trigger_idle_behavior(self):
        """
        é—²æ—¶è§¦å‘ï¼šæ ¹æ®æœ€è¿‘10è½®å¯¹è¯ï¼Œå†³å®šè¯´ä»€ä¹ˆæˆ–åšä»€ä¹ˆã€‚
        è¿”å›: (å›å¤æ–‡æœ¬, åŠ¨ä½œå­—å…¸)
        """
        # å¦‚æœå®Œå…¨æ²¡æœ‰å†å²ï¼ˆåˆšå¯åŠ¨ï¼‰ï¼Œå¯ä»¥ä¸åšä»»ä½•äº‹ï¼Œæˆ–è€…åšä¸ªéšæœºåŠ¨ä½œ
        if not self.history:
            return None, None

        prompt = (
            "ç°åœ¨çš„åœºæ™¯æ˜¯ï¼šç”¨æˆ·æš‚æ—¶æ²¡æœ‰è¯´è¯ï¼Œåœºé¢é™·å…¥äº†æ²‰é»˜ã€‚\n"
            "è¯·è¯»å–ä¸Šæ–¹çš„å¯¹è¯å†å²ï¼Œä½œä¸ºæœºå™¨äººï¼Œè¯·ä¸»åŠ¨æ‰“ç ´æ²‰é»˜ã€‚\n"
            "ä½ å¯ä»¥ï¼š\n"
            "1. é’ˆå¯¹åˆšåˆšçš„è¯é¢˜ç»§ç»­èŠäº›ä¸ä¸€æ ·çš„ä¸œè¥¿ã€‚\n"
            "2. å‘èµ·ä¸€ä¸ªå…¨æ–°çš„æ›´æœ‰è¶£è¯é¢˜ã€‚\n"
            "3. å¿…é¡»é…åˆä¸€ä¸ªç¬¦åˆå½“å‰è¯­å¢ƒçš„åŠ¨ä½œï¼ˆå¦‚ä¼¸æ‡’è…°ã€è½¬åœˆã€æ‘Šæ‰‹ç­‰ï¼‰ã€‚\n"
            "----------------\n"
            f"{get_action_prompt_text()}\n"
            "----------------\n"
            "ã€å¼ºåˆ¶è¿”å›æ ¼å¼ã€‘ï¼šè¯è¯­å†…å®¹ ||| åŠ¨ä½œID\n"
            "ç¤ºä¾‹1: åˆšæ‰èŠå¤ªä¹…äº†ï¼Œæˆ‘å¾—æ´»åŠ¨æ´»åŠ¨ç­‹éª¨ã€‚ ||| 9\n"
            "ç¤ºä¾‹2: ä½ è¿˜åœ¨å—ï¼Ÿæˆ‘éƒ½å¿«ç¡ç€äº†ã€‚ ||| 16\n"
            "å¦‚æœä¸æƒ³åšåŠ¨ä½œï¼ŒIDå¡« -1ã€‚"
        )

        messages = [{"role": "system", "content": prompt}]
        messages.extend(self.history)  # æŠŠå†å²å‘ç»™å®ƒå‚è€ƒ

        # æ¸©åº¦è°ƒé«˜ï¼Œå¢åŠ åˆ›é€ æ€§
        result = self._call_llm(messages, temperature=1.0)
        print(f"ğŸ’¤ Idle Thought: {result}")

        if result and "|||" in result:
            parts = result.split("|||")
            text = parts[0].strip()

            action = None
            try:
                action_id = int(parts[1].strip())
                action = ACTION_MAP.get(action_id)
            except:
                pass

            # è®°å½•è¿™æ¬¡æœºå™¨äººçš„ä¸»åŠ¨å‘è¨€ï¼Œé¿å…ä¸Šä¸‹æ–‡æ–­è£‚
            if text:
                self.update_history("assistant", text)

            return text, action

        return None, None