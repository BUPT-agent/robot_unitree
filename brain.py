from openai import OpenAI
from config import ACTION_MAP, get_action_prompt_text, LLM_API_KEY, LLM_BASE_URL, LLM_MODEL


class RobotBrain:
    def __init__(self):
        self.client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
        self.model = LLM_MODEL
        # åŠ¨ä½œåˆ¤æ–­çš„ Prompt
        self.action_system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªæœºå™¨äººåŠ¨ä½œæŒ‡ä»¤åˆ†ç±»å™¨ã€‚ç”¨æˆ·ä¼šè¾“å…¥ä¸€å¥è¯ï¼Œè¯·åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œç‰©ç†åŠ¨ä½œã€‚\n"
            f"{get_action_prompt_text()}\n"
            "è§„åˆ™ï¼š\n"
            "1. å¦‚æœéœ€è¦æ‰§è¡ŒåŠ¨ä½œï¼Œè¯·ä¸¥æ ¼åªè¿”å›å¯¹åº”çš„ ID æ•°å­—ã€‚\n"
            "2. å¦‚æœä¸éœ€è¦åŠ¨ä½œæˆ–åŠ¨ä½œä¸åœ¨åˆ—è¡¨ä¸­ï¼Œè¯·ä¸¥æ ¼åªè¿”å› -1ã€‚\n"
            "3. åªè¾“å‡ºæ•°å­—ï¼Œä¸è¦æ ‡ç‚¹ã€‚"
        )

    def _call_llm(self, messages, temperature=0.7):
        try:
            # print(f"Messages sent to LLM: {messages}") # è°ƒè¯•ç”¨
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ LLM API Error: {str(e)}")
            return None

    def analyze_action(self, user_text):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡ŒåŠ¨ä½œ"""
        messages = [
            {"role": "system", "content": self.action_system_prompt},
            {"role": "user", "content": user_text}
        ]
        print(messages)
        result = self._call_llm(messages, temperature=0.0)
        print(f"ğŸ§  Action ID Result: [{result}]")

        try:
            action_id = int(result)
            if action_id in ACTION_MAP:
                return ACTION_MAP[action_id]
        except (ValueError, TypeError):
            pass
        return None

    def get_chat_reply(self, user_text, action_data=None):
        """
        è·å–å¯¹è¯å›å¤
        :param user_text: ç”¨æˆ·è¯´çš„è¯
        :param action_data: (å¯é€‰) æœºå™¨äººå³å°†æ‰§è¡Œçš„åŠ¨ä½œå­—å…¸ï¼ŒåŒ…å« 'desc' æè¿°
        """

        # åŸºç¡€äººè®¾
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªUnitree G1æœºå™¨äººåŠ©æ‰‹ï¼Œæ€§æ ¼æ´»æ³¼ã€å¹½é»˜ã€‚è¯·ç”¨å£è¯­åŒ–ã€ç®€çŸ­çš„æ–¹å¼å›ç­”ç”¨æˆ·ï¼Œå­—æ•°æ§åˆ¶åœ¨40å­—ä»¥å†…ã€‚"

        # å…³é”®ä¿®æ”¹ï¼šå¦‚æœè¯†åˆ«å‡ºäº†åŠ¨ä½œï¼Œå°†åŠ¨ä½œä¿¡æ¯æ³¨å…¥åˆ° System Prompt ä¸­
        if action_data:
            action_desc = action_data.get('desc', 'æœªçŸ¥åŠ¨ä½œ')
            system_prompt += (
                f"\nã€é‡è¦ä¸Šä¸‹æ–‡ã€‘ä½ å³å°†æ‰§è¡Œç‰©ç†åŠ¨ä½œï¼šâ€œ{action_desc}â€ã€‚"
                "è¯·åŠ¡å¿…ç»“åˆè¿™ä¸ªåŠ¨ä½œæ¥å›å¤ç”¨æˆ·ï¼Œè®©è¯­è¨€å’ŒåŠ¨ä½œé…åˆè‡ªç„¶ã€‚"
                "ä¾‹å¦‚ï¼šå¦‚æœæ˜¯æ¡æ‰‹ï¼Œå¯ä»¥è¯´'å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ˆä¼¸å‡ºæ‰‹ï¼‰'ã€‚"
            )
        else:
            system_prompt += "\nä½ å½“å‰æ²¡æœ‰æ‰§è¡Œä»»ä½•ç‰©ç†åŠ¨ä½œï¼Œæ­£å¸¸äº¤æµå³å¯ã€‚"

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_text}
        ]
        print(messages)
        return self._call_llm(messages, temperature=0.8)